import streamlit as st
import pickle
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from datetime import datetime

# Page configuration
st.set_page_config(
    page_title="NASA Abstract Classifier",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #ff7f0e;
        margin-top: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Load model files
@st.cache_resource
def load_models():
    """Load all pickle files"""
    try:
        # Load the trained model
        with open('nasa_classifier_model_20260111_113647.pkl', 'rb') as f:
            model = pickle.load(f)
        
        # Load the vectorizer
        with open('tfidf_vectorizer_20260111_113647.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        
        # Load label information
        with open('label_info_20260111_113647.pkl', 'rb') as f:
            label_info = pickle.load(f)
        
        # Load training statistics
        with open('training_stats_20260111_113647.pkl', 'rb') as f:
            stats = pickle.load(f)
        
        return model, vectorizer, label_info, stats
    except FileNotFoundError as e:
        st.error(f"Error loading model files: {e}")
        st.info("Please ensure all .pkl files are in the same directory as this script.")
        return None, None, None, None

# Text cleaning function
def clean_text_advanced(text):
    """Clean and preprocess text"""
    text = text.lower()
    text = re.sub(r'http\S+|www.\S+', '', text)
    text = re.sub(r'\S+@\S+', '', text)
    text = re.sub(r'[^a-z0-9\s.,;:\-]', '', text)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\b\w\b', '', text)
    return text.strip()

# Prediction function
def predict_abstract(input_text, model, vectorizer):
    """Predict category for input abstract"""
    # Clean text
    clean = clean_text_advanced(input_text)
    
    # Vectorize
    vec = vectorizer.transform([clean])
    
    # Predict
    predicted_label = model.predict(vec)[0]
    
    # Get probabilities
    if hasattr(model, 'predict_proba'):
        probs = model.predict_proba(vec)[0]
    elif hasattr(model, 'decision_function'):
        decision = model.decision_function(vec)[0]
        exp_scores = np.exp(decision - np.max(decision))
        probs = exp_scores / exp_scores.sum()
    else:
        probs = np.zeros(len(model.classes_))
        probs[list(model.classes_).index(predicted_label)] = 1.0
    
    classes = model.classes_
    confidence = probs[list(classes).index(predicted_label)] * 100
    
    # Category probabilities
    category_probs = {
        classes[i]: round(probs[i]*100, 2)
        for i in range(len(classes))
    }
    category_probs = dict(sorted(category_probs.items(), key=lambda x: x[1], reverse=True))
    
    # Top keywords
    feature_names = vectorizer.get_feature_names_out()
    tfidf_scores = vec.toarray()[0]
    top_keyword_indices = tfidf_scores.argsort()[-10:][::-1]
    top_keywords = [feature_names[i] for i in top_keyword_indices if tfidf_scores[i] > 0]
    
    # Trend tags
    trends = []
    trend_keywords = {
        'Mars Exploration': ['mars', 'martian', 'rover'],
        'Lunar Science': ['lunar', 'moon'],
        'Spectroscopy': ['spectrometer', 'spectral', 'spectrum'],
        'Remote Sensing': ['remote', 'sensing', 'satellite'],
        'Climate Research': ['climate', 'atmospheric', 'weather'],
        'Space Technology': ['spacecraft', 'satellite', 'mission'],
        'Astrophysics': ['stellar', 'galaxy', 'cosmic', 'universe']
    }
    
    clean_lower = clean.lower()
    for trend, keywords in trend_keywords.items():
        if any(kw in clean_lower for kw in keywords):
            trends.append(trend)
    
    # Readability
    word_count = len(clean.split())
    if word_count > 150:
        readability = "Advanced Scientific"
    elif word_count > 80:
        readability = "Intermediate"
    else:
        readability = "Basic"
    
    # Vocabulary diversity
    unique_words = len(set(clean.split()))
    vocab_diversity = unique_words / word_count if word_count > 0 else 0
    complexity_score = min(100, int(vocab_diversity * 150))
    
    return {
        'predicted_category': predicted_label,
        'confidence': round(confidence, 2),
        'category_probs': category_probs,
        'top_keywords': top_keywords[:10],
        'trends': trends if trends else ['General Space Science'],
        'readability': readability,
        'complexity_score': complexity_score,
        'word_count': word_count,
        'vocab_diversity': round(vocab_diversity, 3)
    }

# Main app
def main():
    # Header
    st.markdown('<p class="main-header">üöÄ NASA Space Mission Abstract Classifier</p>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Load models
    model, vectorizer, label_info, stats = load_models()
    
    if model is None:
        st.stop()
    
    # Sidebar
    st.sidebar.image("https://www.nasa.gov/wp-content/themes/nasa/assets/images/nasa-logo@2x.png", width=200)
    st.sidebar.title("Navigation")
    page = st.sidebar.radio("Go to", ["üè† Home", "üîÆ Classify Abstract", "üìä Model Statistics", "üìà Visualizations"])
    
    st.sidebar.markdown("---")
    st.sidebar.info(f"**Model Accuracy:** {stats.get('final_accuracy', 0)*100:.2f}%")
    st.sidebar.info(f"**Categories:** {stats.get('n_classes', len(label_info['classes']))}")
    st.sidebar.info(f"**Vocabulary Size:** {stats.get('vocabulary_size', 0):,}")
    
    # HOME PAGE
    if page == "üè† Home":
        st.title("Welcome to NASA Abstract Classifier")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total Training Samples", f"{stats.get('train_samples', 0):,}")
        with col2:
            st.metric("Model Accuracy", f"{stats.get('final_accuracy', 0)*100:.2f}%")
        with col3:
            st.metric("F1-Score", f"{stats.get('final_f1', 0):.4f}")
        
        st.markdown("---")
        
        st.markdown("""
        ### üìñ About This Project
        
        This NLP-based system automatically classifies NASA space mission abstracts into scientific categories 
        using advanced Machine Learning and Natural Language Processing techniques.
        
        **Key Features:**
        - üéØ Multi-class classification with high accuracy
        - üîç TF-IDF feature extraction with n-grams
        - üìä Confidence scores and probability distributions
        - üè∑Ô∏è Automatic keyword extraction
        - üìà Trend detection and analysis
        - üéì Readability and complexity assessment
        
        **Categories:**
        """)
        
        categories = label_info.get('classes', stats.get('categories', []))
        cols = st.columns(2)
        for idx, cat in enumerate(categories):
            with cols[idx % 2]:
                st.markdown(f"‚úÖ {cat}")
        
        st.markdown("---")
        st.info("üëà Use the sidebar to navigate to different sections")
    
    # CLASSIFY ABSTRACT PAGE
    elif page == "üîÆ Classify Abstract":
        st.title("Classify Your Abstract")
        
        # Sample abstracts
        sample_abstracts = {
            "Mars Exploration": """This study analyzes the mineral composition of the Martian surface using
            spectrometer data collected during Mars exploration missions. Advanced spectroscopic techniques 
            reveal the presence of various minerals including olivine, pyroxene, and hydrated silicates.""",
            
            "Propulsion System": """Development of a next-generation propulsion system utilizing solar electric
            power for deep space missions. The system incorporates high-efficiency ion thrusters and advanced 
            power management electronics.""",
            
            "Climate Research": """Investigation of atmospheric dynamics and cloud formation patterns on Earth
            using satellite-based remote sensing instruments and climate modeling techniques."""
        }
        
        # Sample selection
        st.subheader("Try a Sample Abstract")
        sample_choice = st.selectbox("Select a sample:", ["None"] + list(sample_abstracts.keys()))
        
        # Text input
        st.subheader("Enter Abstract Text")
        if sample_choice != "None":
            default_text = sample_abstracts[sample_choice]
        else:
            default_text = ""
        
        user_input = st.text_area(
            "Paste your abstract here:",
            value=default_text,
            height=200,
            help="Enter a space mission abstract for classification"
        )
        
        # Classify button
        if st.button("üöÄ Classify Abstract", type="primary"):
            if user_input.strip():
                with st.spinner("Analyzing abstract..."):
                    result = predict_abstract(user_input, model, vectorizer)
                
                # Display results
                st.markdown('<div class="prediction-box">', unsafe_allow_html=True)
                st.markdown(f"## üéØ Predicted Category: {result['predicted_category']}")
                st.markdown(f"### Confidence: {result['confidence']:.2f}%")
                st.markdown('</div>', unsafe_allow_html=True)
                
                # Metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Word Count", result['word_count'])
                with col2:
                    st.metric("Complexity Score", f"{result['complexity_score']}/100")
                with col3:
                    st.metric("Readability", result['readability'])
                with col4:
                    st.metric("Vocab Diversity", f"{result['vocab_diversity']:.3f}")
                
                st.markdown("---")
                
                # Two column layout
                col_left, col_right = st.columns(2)
                
                with col_left:
                    # Probability distribution
                    st.subheader("üìä Category Probabilities")
                    prob_df = pd.DataFrame({
                        'Category': list(result['category_probs'].keys()),
                        'Probability (%)': list(result['category_probs'].values())
                    })
                    
                    fig = px.bar(
                        prob_df,
                        x='Probability (%)',
                        y='Category',
                        orientation='h',
                        color='Probability (%)',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_layout(height=400, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)
                
                with col_right:
                    # Top keywords
                    st.subheader("üîë Top Keywords")
                    keywords_text = ", ".join(result['top_keywords'])
                    st.info(keywords_text)
                    
                    # Trends
                    st.subheader("üìà Detected Trends")
                    for trend in result['trends']:
                        st.success(f"‚úÖ {trend}")
                    
                    # Probability table
                    st.subheader("üìã Detailed Probabilities")
                    st.dataframe(
                        prob_df.style.background_gradient(subset=['Probability (%)'], cmap='YlOrRd'),
                        use_container_width=True
                    )
            else:
                st.warning("‚ö†Ô∏è Please enter some text to classify")
    
    # MODEL STATISTICS PAGE
    elif page == "üìä Model Statistics":
        st.title("Model Statistics & Performance")
        
        # Overview metrics
        st.subheader("üìà Performance Overview")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Best Model",
                stats.get('best_model', 'N/A'),
                help="Model with highest F1-score"
            )
        with col2:
            st.metric(
                "Accuracy",
                f"{stats.get('final_accuracy', 0)*100:.2f}%"
            )
        with col3:
            st.metric(
                "F1-Score",
                f"{stats.get('final_f1', 0):.4f}"
            )
        with col4:
            st.metric(
                "Total Samples",
                f"{stats.get('total_samples', 0):,}"
            )
        
        st.markdown("---")
        
        # Training configuration
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üîß Training Configuration")
            config_data = {
                "Parameter": [
                    "Total Samples",
                    "Training Samples",
                    "Testing Samples",
                    "Vocabulary Size",
                    "Number of Categories"
                ],
                "Value": [
                    f"{stats.get('total_samples', 0):,}",
                    f"{stats.get('train_samples', 0):,}",
                    f"{stats.get('test_samples', 0):,}",
                    f"{stats.get('vocabulary_size', 0):,}",
                    f"{len(label_info.get('classes', []))}"
                ]
            }
            st.table(pd.DataFrame(config_data))
        
        with col2:
            st.subheader("üìÅ Model Information")
            model_data = {
                "Aspect": [
                    "Algorithm",
                    "Feature Extraction",
                    "N-gram Range",
                    "Training Date",
                    "Model Classes"
                ],
                "Details": [
                    stats.get('best_model', 'Logistic Regression'),
                    "TF-IDF",
                    "1-3 grams",
                    label_info.get('training_date', 'N/A'),
                    f"{label_info.get('n_classes', 0)} categories"
                ]
            }
            st.table(pd.DataFrame(model_data))
        
        st.markdown("---")
        
        # Categories list
        st.subheader("üè∑Ô∏è Classification Categories")
        categories = label_info.get('classes', stats.get('categories', []))
        
        cols = st.columns(3)
        for idx, cat in enumerate(categories):
            with cols[idx % 3]:
                st.success(f"‚úÖ {cat}")
    
    # VISUALIZATIONS PAGE
    elif page == "üìà Visualizations":
        st.title("Data Visualizations")
        
        # Train/Test split visualization
        st.subheader("üìä Train-Test Split Distribution")
        
        split_data = pd.DataFrame({
            'Dataset': ['Training', 'Testing'],
            'Samples': [stats.get('train_samples', 0), stats.get('test_samples', 0)]
        })
        
        fig = px.pie(
            split_data,
            values='Samples',
            names='Dataset',
            color_discrete_sequence=['#636EFA', '#EF553B'],
            hole=0.4
        )
        fig.update_traces(textposition='inside', textinfo='percent+label+value')
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        # Categories visualization
        st.subheader("üìã Category Distribution")
        
        categories = label_info.get('classes', stats.get('categories', []))
        # Create sample distribution (in real app, this would come from actual data)
        category_counts = np.random.randint(500, 3000, len(categories))
        
        cat_df = pd.DataFrame({
            'Category': categories,
            'Count': category_counts
        }).sort_values('Count', ascending=True)
        
        fig = px.bar(
            cat_df,
            x='Count',
            y='Category',
            orientation='h',
            color='Count',
            color_continuous_scale='Plasma',
            title='Number of Abstracts per Category'
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        # Model comparison (simulated data)
        st.subheader("üèÜ Model Performance Comparison")
        
        model_comparison = pd.DataFrame({
            'Model': ['Logistic Regression', 'Naive Bayes', 'Linear SVM', 'Random Forest'],
            'F1-Score': [0.8842, 0.8523, 0.8756, 0.8634],
            'Accuracy': [0.8876, 0.8534, 0.8798, 0.8687]
        })
        
        fig = go.Figure()
        fig.add_trace(go.Bar(
            name='F1-Score',
            x=model_comparison['Model'],
            y=model_comparison['F1-Score'],
            marker_color='lightblue'
        ))
        fig.add_trace(go.Bar(
            name='Accuracy',
            x=model_comparison['Model'],
            y=model_comparison['Accuracy'],
            marker_color='lightcoral'
        ))
        
        fig.update_layout(
            barmode='group',
            height=400,
            title='Model Performance Metrics',
            yaxis_title='Score'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        # Performance gauge
        st.subheader("üéØ Overall Model Performance")
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=stats.get('final_accuracy', 0) * 100,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Accuracy (%)"},
                delta={'reference': 85},
                gauge={
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 75], 'color': "gray"},
                        {'range': [75, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=stats.get('final_f1', 0) * 100,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "F1-Score (%)"},
                gauge={
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkgreen"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 75], 'color': "gray"},
                        {'range': [75, 100], 'color': "lightblue"}
                    ]
                }
            ))
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray;'>
            <p>üöÄ NASA Space Mission Abstract Classifier | Powered by Machine Learning & NLP</p>
            <p>Built with Streamlit | ¬© 2026</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()